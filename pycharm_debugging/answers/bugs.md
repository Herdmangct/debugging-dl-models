### The bugs:

- `float_32` instead of `float32`, `-1000` for the `n_samples`
- shape mismatch in loss
- learning rate too low
- only 1 trainable layer
- disconnected layers
- y_pred, y_pred for the loss
- tanh in the first layer
- relu in the last layer
